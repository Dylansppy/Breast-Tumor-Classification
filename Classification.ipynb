{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to Describe Features extracted\n",
    "def describeData(X,y):\n",
    "    print('Total number of images: {}'.format(len(X)))\n",
    "    print('Number of Benign Images: {}'.format(np.sum(y==0)))\n",
    "    print('Number of Malignant Images: {}'.format(np.sum(y==1)))\n",
    "    print('Percentage of positive images: {:.2f}%'.format(100*np.mean(y)))\n",
    "    print('Image shape (Samples, Rows, Columns, Features): {}'.format(X[0].shape))\n",
    "    print()\n",
    "\n",
    "def feature_dimension(train_or_test, model, factor):\n",
    "    X = np.load('../data/features_' + model + '/'+ train_or_test + '/' + str(factor)+'/X.npy')\n",
    "    y = np.load('../data/features_' + model + '/'+ train_or_test + '/' + str(factor)+'/y.npy')\n",
    "    print('Discription of ' + str(factor) + 'x images and features extracted by ' + model)\n",
    "    describeData(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discription of 40x images and features extracted by xception\n",
      "Total number of images: 1367\n",
      "Number of Benign Images: 428\n",
      "Number of Malignant Images: 939\n",
      "Percentage of positive images: 68.69%\n",
      "Image shape (Samples, Rows, Columns, Features): (1, 10, 10, 2048)\n",
      "\n",
      "Discription of 100x images and features extracted by xception\n",
      "Total number of images: 1449\n",
      "Number of Benign Images: 439\n",
      "Number of Malignant Images: 1010\n",
      "Percentage of positive images: 69.70%\n",
      "Image shape (Samples, Rows, Columns, Features): (1, 10, 10, 2048)\n",
      "\n",
      "Discription of 200x images and features extracted by xception\n",
      "Total number of images: 1383\n",
      "Number of Benign Images: 412\n",
      "Number of Malignant Images: 971\n",
      "Percentage of positive images: 70.21%\n",
      "Image shape (Samples, Rows, Columns, Features): (1, 10, 10, 2048)\n",
      "\n",
      "Discription of 400x images and features extracted by xception\n",
      "Total number of images: 1274\n",
      "Number of Benign Images: 410\n",
      "Number of Malignant Images: 864\n",
      "Percentage of positive images: 67.82%\n",
      "Image shape (Samples, Rows, Columns, Features): (1, 10, 10, 2048)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check feature dimension extracted by Xception\n",
    "feature_dimension('train', 'xception', 40)\n",
    "feature_dimension('train', 'xception', 100)\n",
    "feature_dimension('train', 'xception', 200)\n",
    "feature_dimension('train', 'xception', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discription of 40x images and features extracted by vgg16\n",
      "Total number of images: 1367\n",
      "Number of Benign Images: 428\n",
      "Number of Malignant Images: 939\n",
      "Percentage of positive images: 68.69%\n",
      "Image shape (Samples, Rows, Columns, Features): (1, 7, 7, 512)\n",
      "\n",
      "Discription of 100x images and features extracted by vgg16\n",
      "Total number of images: 1449\n",
      "Number of Benign Images: 439\n",
      "Number of Malignant Images: 1010\n",
      "Percentage of positive images: 69.70%\n",
      "Image shape (Samples, Rows, Columns, Features): (1, 7, 7, 512)\n",
      "\n",
      "Discription of 200x images and features extracted by vgg16\n",
      "Total number of images: 1383\n",
      "Number of Benign Images: 412\n",
      "Number of Malignant Images: 971\n",
      "Percentage of positive images: 70.21%\n",
      "Image shape (Samples, Rows, Columns, Features): (1, 7, 7, 512)\n",
      "\n",
      "Discription of 400x images and features extracted by vgg16\n",
      "Total number of images: 1274\n",
      "Number of Benign Images: 410\n",
      "Number of Malignant Images: 864\n",
      "Percentage of positive images: 67.82%\n",
      "Image shape (Samples, Rows, Columns, Features): (1, 7, 7, 512)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check feature dimension extracted by VGG16\n",
    "feature_dimension('train', 'vgg16', 40)\n",
    "feature_dimension('train', 'vgg16', 100)\n",
    "feature_dimension('train', 'vgg16', 200)\n",
    "feature_dimension('train', 'vgg16', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discription of 40x images and features extracted by vgg19\n",
      "Total number of images: 1367\n",
      "Number of Benign Images: 428\n",
      "Number of Malignant Images: 939\n",
      "Percentage of positive images: 68.69%\n",
      "Image shape (Samples, Rows, Columns, Features): (1, 14, 14, 512)\n",
      "\n",
      "Discription of 100x images and features extracted by vgg19\n",
      "Total number of images: 1449\n",
      "Number of Benign Images: 439\n",
      "Number of Malignant Images: 1010\n",
      "Percentage of positive images: 69.70%\n",
      "Image shape (Samples, Rows, Columns, Features): (1, 14, 14, 512)\n",
      "\n",
      "Discription of 200x images and features extracted by vgg19\n",
      "Total number of images: 1383\n",
      "Number of Benign Images: 412\n",
      "Number of Malignant Images: 971\n",
      "Percentage of positive images: 70.21%\n",
      "Image shape (Samples, Rows, Columns, Features): (1, 14, 14, 512)\n",
      "\n",
      "Discription of 400x images and features extracted by vgg19\n",
      "Total number of images: 1274\n",
      "Number of Benign Images: 410\n",
      "Number of Malignant Images: 864\n",
      "Percentage of positive images: 67.82%\n",
      "Image shape (Samples, Rows, Columns, Features): (1, 14, 14, 512)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check feature dimension extracted by VGG19\n",
    "feature_dimension('train', 'vgg19', 40)\n",
    "feature_dimension('train', 'vgg19', 100)\n",
    "feature_dimension('train', 'vgg19', 200)\n",
    "feature_dimension('train', 'vgg19', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of pre-trained CNN model xception for images at 40x:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.65      0.65      0.65       197\n",
      "   Malignant       0.84      0.84      0.84       431\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       628\n",
      "   macro avg       0.74      0.75      0.74       628\n",
      "weighted avg       0.78      0.78      0.78       628\n",
      "\n",
      "F1 Score: 0.8381839348079162\n",
      "\n",
      "Performance of pre-trained CNN model vgg16 for images at 40x:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.57      0.56      0.56       197\n",
      "   Malignant       0.80      0.81      0.80       431\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       628\n",
      "   macro avg       0.68      0.68      0.68       628\n",
      "weighted avg       0.73      0.73      0.73       628\n",
      "\n",
      "F1 Score: 0.8023121387283237\n",
      "\n",
      "Performance of pre-trained CNN model vgg19 for images at 40x:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.54      0.47      0.50       197\n",
      "   Malignant       0.77      0.82      0.79       431\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       628\n",
      "   macro avg       0.66      0.64      0.65       628\n",
      "weighted avg       0.70      0.71      0.70       628\n",
      "\n",
      "F1 Score: 0.7941507311586051\n",
      "\n",
      "Performance of pre-trained CNN model xception for images at 100x:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.61      0.54      0.57       205\n",
      "   Malignant       0.79      0.84      0.81       427\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       632\n",
      "   macro avg       0.70      0.69      0.69       632\n",
      "weighted avg       0.73      0.74      0.74       632\n",
      "\n",
      "F1 Score: 0.8136363636363637\n",
      "\n",
      "Performance of pre-trained CNN model vgg16 for images at 100x:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.54      0.49      0.51       205\n",
      "   Malignant       0.77      0.80      0.78       427\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       632\n",
      "   macro avg       0.65      0.64      0.65       632\n",
      "weighted avg       0.69      0.70      0.69       632\n",
      "\n",
      "F1 Score: 0.7807118254879448\n",
      "\n",
      "Performance of pre-trained CNN model vgg19 for images at 100x:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.57      0.39      0.46       205\n",
      "   Malignant       0.74      0.86      0.80       427\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       632\n",
      "   macro avg       0.66      0.62      0.63       632\n",
      "weighted avg       0.69      0.71      0.69       632\n",
      "\n",
      "F1 Score: 0.7991313789359392\n",
      "\n",
      "Performance of pre-trained CNN model xception for images at 200x:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.65      0.51      0.57       211\n",
      "   Malignant       0.78      0.86      0.82       419\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       630\n",
      "   macro avg       0.71      0.69      0.69       630\n",
      "weighted avg       0.74      0.74      0.74       630\n",
      "\n",
      "F1 Score: 0.8180790960451978\n",
      "\n",
      "Performance of pre-trained CNN model vgg16 for images at 200x:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.55      0.45      0.49       211\n",
      "   Malignant       0.75      0.82      0.78       419\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       630\n",
      "   macro avg       0.65      0.63      0.64       630\n",
      "weighted avg       0.68      0.69      0.68       630\n",
      "\n",
      "F1 Score: 0.7790432801822323\n",
      "\n",
      "Performance of pre-trained CNN model vgg19 for images at 200x:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.49      0.37      0.43       211\n",
      "   Malignant       0.72      0.81      0.76       419\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       630\n",
      "   macro avg       0.61      0.59      0.59       630\n",
      "weighted avg       0.64      0.66      0.65       630\n",
      "\n",
      "F1 Score: 0.7604049493813273\n",
      "\n",
      "Performance of pre-trained CNN model xception for images at 400x:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.54      0.47      0.50       178\n",
      "   Malignant       0.76      0.81      0.78       368\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       546\n",
      "   macro avg       0.65      0.64      0.64       546\n",
      "weighted avg       0.69      0.70      0.69       546\n",
      "\n",
      "F1 Score: 0.7826086956521738\n",
      "\n",
      "Performance of pre-trained CNN model vgg16 for images at 400x:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.48      0.44      0.46       178\n",
      "   Malignant       0.74      0.76      0.75       368\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       546\n",
      "   macro avg       0.61      0.60      0.61       546\n",
      "weighted avg       0.65      0.66      0.66       546\n",
      "\n",
      "F1 Score: 0.7513368983957219\n",
      "\n",
      "Performance of pre-trained CNN model vgg19 for images at 400x:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Benign       0.45      0.35      0.40       178\n",
      "   Malignant       0.72      0.79      0.75       368\n",
      "\n",
      "   micro avg       0.65      0.65      0.65       546\n",
      "   macro avg       0.59      0.57      0.58       546\n",
      "weighted avg       0.63      0.65      0.64       546\n",
      "\n",
      "F1 Score: 0.7535483870967741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using Logistic Regression as Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = [\"Benign\",  \n",
    "          \"Malignant\"]\n",
    "\n",
    "def runLogisticRegression(a,b,c,d):\n",
    "    \"\"\"Run LogisticRegression as Classifier\"\"\"\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    clf = model.fit(a,b)\n",
    "    preds = clf.predict(c)\n",
    "    print(classification_report(d, preds, target_names=labels))\n",
    "    #print(\"acc: %.02f\" % accuracy_score(d, preds))\n",
    "    print(\"F1 Score: {}\".format(f1_score(d, preds)))\n",
    "    #kfold = model_selection.KFold(n_splits=10)\n",
    "    #f1= model_selection.cross_val_score(model, c,d, cv=kfold, scoring='f1')\n",
    "    #mean = f1.mean() \n",
    "    #stdev = f1.std()\n",
    "    #print('F1 score: %s (%s)' % (mean, stdev))\n",
    "    print('')\n",
    "    \n",
    "\n",
    "def Model_Performance(model, magnification_factor):\n",
    "    # Make Data 1D for compatability with standard classifiers\n",
    "    X_train=np.load('../data/features_' + model + '/Train/' + magnification_factor +'/X.npy')\n",
    "    X_trainShape = X_train.shape[1]*X_train.shape[2]*X_train.shape[3]*X_train.shape[4]\n",
    "    X_trainFlat = X_train.reshape(X_train.shape[0], X_trainShape)\n",
    "    y_train = np.load('../data/features_' + model  + '/Train/' +magnification_factor+'/y.npy')\n",
    "    \n",
    "    X_test=np.load('../data/features_' + model  + '/Test/' + magnification_factor+'/X.npy')\n",
    "    X_testShape = X_test.shape[1]*X_test.shape[2]*X_test.shape[3]*X_test.shape[4]\n",
    "    X_testFlat = X_test.reshape(X_test.shape[0], X_testShape)\n",
    "    y_test = np.load('../data/features_' + model  + '/Test/' + magnification_factor+'/y.npy')\n",
    "    \n",
    "    print('Performance of pre-trained CNN model ' + model + ' for images at ' + magnification_factor + 'x:')\n",
    "    runLogisticRegression(X_trainFlat, y_train, X_testFlat, y_test)\n",
    "\n",
    "magnification_factors = ['40', '100', '200', '400']\n",
    "for factor in magnification_factors:\n",
    "    Model_Performance('xception', factor)\n",
    "    Model_Performance('vgg16', factor)\n",
    "    Model_Performance('vgg19', factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Performance of Different Classification Algorithms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifiers = []\n",
    "classifiers.append(('LR', LogisticRegression()))\n",
    "classifiers.append(('RF', RandomForestClassifier()))\n",
    "classifiers.append(('KNN', KNeighborsClassifier()))\n",
    "classifiers.append(('SVM', SVC()))\n",
    "classifiers.append(('LSVM', LinearSVC()))\n",
    "classifiers.append(('GNB', GaussianNB()))\n",
    "classifiers.append(('DTC', DecisionTreeClassifier()))\n",
    "#classifiers.append(('GBC', GradientBoostingClassifier()))\n",
    "#classifiers.append(('LDA', LinearDiscriminantAnalysis())) \n",
    "\n",
    "def defineModels():\n",
    "    \"\"\"\n",
    "    This function just defines each abbreviation used in the previous function (e.g. LR = Logistic Regression)\n",
    "    \"\"\"\n",
    "    print('')\n",
    "    print('LR = LogisticRegression')\n",
    "    print('RF = RandomForestClassifier')\n",
    "    print('KNN = KNeighborsClassifier')\n",
    "    print('SVM = Support Vector Machine SVC')\n",
    "    print('LSVM = LinearSVC')\n",
    "    print('GNB = GaussianNB')\n",
    "    print('DTC = DecisionTreeClassifier')\n",
    "    #print('GBC = GradientBoostingClassifier')\n",
    "    #print('LDA = LinearDiscriminantAnalysis')\n",
    "    print('')\n",
    "    return\n",
    "defineModels()\n",
    "    \n",
    "def compareABunchOfDifferentModelsAccuracy(a,b,c,d):\n",
    "    \"\"\"\n",
    "    compare performance of classifiers on X_train, X_test, Y_train, Y_test\n",
    "    http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score\n",
    "    http://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score\n",
    "    \"\"\"    \n",
    "    print('')\n",
    "    print('Compare Multiple Classifiers:')\n",
    "    print('')\n",
    "    print('K-Fold Cross-Validation Accuracy:')\n",
    "    print('')      \n",
    "    resultsAccuracy = []\n",
    "    names = []\n",
    "    for name, model in classifiers:\n",
    "        model.fit(a, b)\n",
    "        kfold = model_selection.KFold(n_splits=10)\n",
    "        accuracy_results = model_selection.cross_val_score(model, c, d, cv=kfold, scoring='accuracy')\n",
    "        resultsAccuracy.append(accuracy_results)\n",
    "        names.append(name)\n",
    "        accuracyMessage = \"%s: %f (%f)\" % (name, accuracy_results.mean(), accuracy_results.std())\n",
    "        print(accuracyMessage)  \n",
    "    # boxplot algorithm comparison\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Algorithm Comparison: Accuracy')\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.boxplot(resultsAccuracy)\n",
    "    ax.set_xticklabels(names)\n",
    "    ax.set_ylabel('Cross-Validation: Accuracy Score')\n",
    "    plt.show()\n",
    "    return\n",
    "compareABunchOfDifferentModelsAccuracy(X_trainFlat, Y_train, X_testFlat, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(X)):\n",
    "    x=GlobalAveragePooling2D()(x)\n",
    "    x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "    x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "    x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "    preds=Dense(2,activation='softmax')(x) #final layer with softmax activation\n",
    "\n",
    "def classification_training(train_or_test, feature_extractor, factor):\n",
    "    X = np.load('../data/features_' + model + '/'+ train_or_test + '/' + str(factor)+'/X.npy')\n",
    "    y = np.load('../data/features_' + model + '/'+ train_or_test + '/' + str(factor)+'/y.npy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
